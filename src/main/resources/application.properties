quarkus.application.name=embedder

# JVM args for JDK 21+ reflection access and memory settings
quarkus.native.additional-build-args=--add-opens,java.base/java.lang=ALL-UNNAMED,-J-Xmx10g
%dev.quarkus.jvm.args=--add-opens java.base/java.lang=ALL-UNNAMED

# Production port allocation
quarkus.http.port=39003
quarkus.http.host=0.0.0.0
quarkus.grpc.server.use-separate-server=false

# Development override
%dev.quarkus.http.port=39003
%dev.quarkus.http.host=0.0.0.0

# gRPC Client pointing to registration service via Stork/Consul
quarkus.grpc.clients.registration-service.host=registration-service
quarkus.grpc.clients.registration-service.name-resolver=stork

# gRPC Client for the embedder service (used by REST endpoints)
quarkus.grpc.clients.embedder.host=localhost
quarkus.grpc.clients.embedder.port=39003

# Stork service discovery configuration
quarkus.stork.registration-service.service-discovery.type=consul
quarkus.stork.registration-service.service-discovery.consul-host=${CONSUL_HOST:consul}
quarkus.stork.registration-service.service-discovery.consul-port=${CONSUL_PORT:8500}

# Development override - use localhost Consul in dev mode  
%dev.quarkus.stork.registration-service.service-discovery.consul-host=localhost

# Module Registration Configuration
module.registration.enabled=true
module.registration.module-name=embedder
module.registration.host=${MODULE_HOST:host.docker.internal}
module.registration.port=${quarkus.http.port}
module.registration.description=Vector embedding module for semantic processing using deep learning models
module.registration.capabilities=vector-embedding,semantic-processing,ml-inference,djl
module.registration.tags=embedder,ml,vector,semantic,module

# Disable for tests
%test.module.registration.enabled=false

# Module configuration
module.name=embedder
module.type=processor
module.description=Vector embedding module for semantic processing

# Enable gRPC reflection service for production (enabled by default in dev)
quarkus.grpc.server.enable-reflection-service=true

# Health check configuration - use localhost for local development
module.health.check.host=localhost

# Enable OpenAPI and Swagger UI
quarkus.swagger-ui.always-include=true
quarkus.swagger-ui.path=/swagger-ui

# gRPC Message Size Configuration (2GB - 1 byte, max int value)
quarkus.grpc.server.max-inbound-message-size=2147483647
quarkus.grpc.clients.embedder.max-inbound-message-size=2147483647

# Set gRPC message size limits for all clients (wildcard)
quarkus.grpc.clients."*".max-inbound-message-size=2147483647
quarkus.grpc.clients."*".max-outbound-message-size=2147483647

# Logging Configuration - reduce noise
quarkus.log.level=INFO
quarkus.log.category."io.pipeline".level=DEBUG
quarkus.log.category."io.vertx.ext.consul".level=WARN
quarkus.log.category."io.quarkus.grpc".level=WARN

# JVM devservices timeout
%dev.quarkus.devservices.timeout=120s

# JVM heap settings for embedder processing
quarkus.jvm.args=-Xmx10g,-Xms2g,-XX:+UseG1GC,-XX:MaxGCPauseMillis=200

# Test settings  
%test.quarkus.http.port=0

# Test gRPC client configuration for @GrpcClient without name (uses stork://grpc-server by default)
%test.quarkus.grpc.clients.grpc-server.max-inbound-message-size=2147483647
%test.quarkus.grpc.clients.grpc-server.max-outbound-message-size=2147483647

# Test wildcard gRPC client configuration (ensure 2GB limits apply in test mode too)
%test.quarkus.grpc.clients."*".max-inbound-message-size=2147483647
%test.quarkus.grpc.clients."*".max-outbound-message-size=2147483647

# gRPC timeout configuration for long-running embedding operations (10 minutes)
quarkus.grpc.server.deadline=600s
quarkus.grpc.clients."*".deadline=600s
%test.quarkus.grpc.clients."*".deadline=600s


##TODO: leaving this in her for now, but I believe this all comes from the configuration options in our schema
# DJL configuration for ML models
djl.engine.default-engine=PyTorch
# Use GPU if available, otherwise fallback to CPU
djl.pytorch.use-gpu=true
# Number of threads for CPU inference
djl.pytorch.num-threads=4
# Memory management
djl.pytorch.memory-management=ON_SYSTEM_MEMORY_PRESSURE

##TODO: this should be working... we probably removed it at one point?
# Processing buffer configuration
processing.buffer.enabled=${PROCESSING_BUFFER_ENABLED:false}
processing.buffer.capacity=${PROCESSING_BUFFER_CAPACITY:100}
processing.buffer.directory=${PROCESSING_BUFFER_DIRECTORY:}
processing.buffer.prefix=${PROCESSING_BUFFER_PREFIX:embedder_output}


# Compose Dev Services - Let Quarkus manage the compose file automatically
%dev.quarkus.compose.devservices.files=../../src/test/resources/compose-devservices.yml
%dev.quarkus.compose.devservices.start-services=true
%dev.quarkus.compose.devservices.stop-services=false
%dev.quarkus.compose.devservices.project-name=pipeline-shared-devservices
